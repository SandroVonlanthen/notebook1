{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social Computing: Notebook 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please include your names below and edit the name of the file to include the last names of the people answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Students: ..., ...Maximilian Kiefer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Feature extraction (30 points total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise you are provided with a dataset of hashed email addresses. This dataset can be found in hashedEmailAddressesGitHubCommits.csv, at https://www.dropbox.com/s/kevcp917ok9qyn0/hashedEmailAddressesGitHubCommits.csv.zip?dl=0. Please make sure you can access this file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying the country of residence\n",
    "\n",
    "**Exercise 1.1 (12 points)**\n",
    "\n",
    "Based on the email address, we can infer different properties about the user. One example is their country of residence. For example, an email like “1315ae6229444367968a943a219f38def9a8112d@vpn-251-169.epfl.ch” will probably correspond to a user located in Switzerland, while an email of the form “59bd0a3ff43b32849b319e645d4798d8a5d1e889@philipphauer.de” will probably correspond to a user located in Germany. \n",
    "\n",
    "Write a script that classifies the email addresses from the file above, based on the country of residence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python extract_emails_from_https://www.dropbox.com/s/kevcp917ok9qyn0/hashedEmailAddressesGitHubCommits.csv.zip?dl=0 \n",
    "def sorting(filename):\n",
    "  infile = open(filename)\n",
    "  words = []\n",
    "  for country of residence in infile:\n",
    "    temp = line.split()\n",
    "    for i in temp:\n",
    "      words.append(i)\n",
    "  infile.close()\n",
    "  words.sort()\n",
    "  outfile = open(\"https://www.dropbox.com/s/kevcp917ok9qyn0/hashedEmailAddressesGitHubCommits.csv.zip?dl=0\", \"w\")\n",
    "  for i in words:\n",
    "    outfile.writelines(i)\n",
    "    outfile.writelines(\" \")\n",
    "  outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.2 (6 points)**\n",
    "\n",
    "Select 100 email addresses from the list. Each member of the team should manually evaluate them (separately)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_file = open(\"hashedEmailAddressesGitHubCommits.csv\")\n",
    "Open \"hashedEmailAddressesGitHubCommits.csv\"\n",
    "\n",
    "\n",
    "number_of_lines = 100\n",
    "\n",
    "for i in range(number_of_lines):\n",
    "Print the first number_of_lines lines of a_file\n",
    "\n",
    "    line = a_file.readline()\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, compare your results. Did you agree on all the 100 entries? Were you able to label all email addresses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yes I agree with it. I can label all the email addresses with the code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.3 (9 points)**\n",
    "\n",
    "Now, evaluate the coverage and the accuracy of your algorithm by comparing your labels with the algorithm's result. \n",
    " -  Based on the random sample, what % of the data can your algorithm classify? Can you add something to your code to increase it? If, yes, include below your updated code. How much did coverage increase?\n",
    " - Based on the classified items on your list, what % did your algorithm classify correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import collections\n",
    "\n",
    "\n",
    "def main():\n",
    "    with open('mailbox.txt') as mbox:\n",
    "        ndict = collections.defaultdict(int)\n",
    "        for line in mbox:\n",
    "            domain = re.findall('From [^ ].*@([^ ]*)', line)\n",
    "            if domain:\n",
    "                ndict[domain[0]] += 1\n",
    "\n",
    "        for item in sorted(ndict.items(), key=lambda x: x[1], reverse=True):\n",
    "            print(item)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "We should get full coverage as we are sorting email addresses according to the number of occurrences of each domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.4 (3 points)**\n",
    "The country of residence is not the only characteristic of the user that can be inferred from their email address. Make a short list of other characteristics that you could infer from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Name, business affliation, university education"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Rate limiting (15 points total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2.1 (2 points)**\n",
    "\n",
    "By now, you are familiar with a few APIs, namely Google Books and NYT. For both of them, find the rules about rate limits and summarise them below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google Books: By default, it is set to 100 requests per 100 seconds per user and can be adjusted to a maximum value of 1,000. But the number of requests to the API is restricted to a maximum of 10 requests per second per user.\n",
    "    \n",
    "NYT:  Yes, there are two rate limits per API: 4,000 requests per day and 10 requests per minute. You should sleep 6 seconds between calls to avoid hitting the per minute rate limit. If you need a higher rate limit, please contact us at code@nytimes.com.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2.2 (8 points)**\n",
    "\n",
    "Next, pick one of these two APIs and try to exceed the rate limit. What reaction do you get from the API? Comment your code to make your logic clear!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "If this limit is exceeded or if CPU or total time limits are exceeded, the app or user may be throttled. \n",
    "API requests made by a throttled user or app will fail. All API requests are subject to rate limits.\n",
    "\n",
    "def send_request(date):\n",
    "    '''Sends a request to the NYT Archive API for given date.'''\n",
    "    base_url = 'https://api.nytimes.com/svc/archive/v1/'\n",
    "    url = base_url + '/' + date[0] + '/' + date[1] + '.json?api-key=' + YOUR_API_KEY\n",
    "    try:\n",
    "        response = requests.get(url, verify=False).json()\n",
    "    except Exception:\n",
    "        return None\n",
    "    finally:\n",
    "        time.sleep(6)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2.3 (5 points)**\n",
    "\n",
    "In the next problem you will check how many requests you can send to Google Search before getting blocked. Websites protect themselves from automated crawling by checking requests that come from the same computer in a small time frame and after a while, they won't respond to the request. A valid response would be \"Response 200\", which you can see if you just print the response of `requests.get('https://www.google.com/search?q=zurich')`. \n",
    "\n",
    "Write code to find out how many requests does it take to get blocked (when you first get a response other than 200). In addition, write what is the number of a blocked response and what does it stand for (Google response XXX)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for company_name in data:\n",
    "    search = company_name\n",
    "    results = 1\n",
    "\n",
    "    s = requests.Session()\n",
    "    retries = Retry(total=3, backoff_factor=0.5)\n",
    "    s.mount('http://', HTTPAdapter(max_retries=retries))\n",
    "    s.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "    page = s.get(\"https://www.google.com/search?q={}&num={}\".format(search, results))\n",
    "    time.sleep(.600)\n",
    "\n",
    "    soup = BeautifulSoup(page.content, \"html5lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Selenium (55 points total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start: Selenium Download\n",
    "For the next exercises you will have to use Selenium. \n",
    "\n",
    "You can read more about the webdriver here (https://chromedriver.chromium.org), but if you want to go straight to the download, go to https://chromedriver.storage.googleapis.com/index.html?path=89.0.4389.23/ and download your version. \n",
    "\n",
    "The steps to get Selenium to work are:\n",
    "1. download webdriver\n",
    "2. extract\n",
    "3. Add to Path\n",
    "4. install selenium from terminal (e.g. `pip install selenium`)\n",
    "\n",
    "Once this is done, you should be able to run:\n",
    "- `from selenium import webdriver`\n",
    "- `browser = webdriver.Chrome([the path where you put the googlechromedriver])`\n",
    "\n",
    "In case of any issues, the https://chromedriver.chromium.org website has some straightforward info on common bugs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selenium Sessions\n",
    "\n",
    "**Exercise 3.1 (25 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to a website of your choice where you have an account. It can for example be the New York Times APi website where you created a login last time but also tutti.ch, comparis, whatever simple website you often use.\n",
    "\n",
    "Using Selenium create a session where you \n",
    "1. go to the main website \n",
    "2. log in \n",
    "3. click on an element of your choice \n",
    "4. scroll to the bottom of the page\n",
    "5. then save the page. \n",
    "\n",
    "When logging in, you will have to find the name of the login form and submit your credentials to it and then click the login button. Here you find an example for a login using selenium but in case you decide to use this help, Facebook should not be your chosen website. https://crossbrowsertesting.com/blog/test-automation/automate-login-with-selenium/\n",
    " \n",
    "Tip: Website uses captcha? You can put your script to sleep for some number of seconds by using time.sleep() function and enter captcha manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import os\n",
    "\n",
    "import time\n",
    "from venv import create\n",
    "from selenium import webdriver\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "options= webdriver.FirefoxOptions()\n",
    "options.headless=True\n",
    "\n",
    "driver = webdriver.Firefox()\n",
    "\n",
    "\n",
    "driver.get(\"https://www.chess.com/login_and_go?returnUrl=https://www.chess.com/\")\n",
    "element = driver.find_element(by=By.ID, value=\"username\")\n",
    "element.send_keys(\"Notebook3\")\n",
    "element = driver.find_element(by=By.ID, value=\"password\")\n",
    "element.send_keys(\"Notebook3SocialComputing\")\n",
    "element = driver.find_element(by=By.ID, value=\"login\")\n",
    "element .click()\n",
    "element = driver.find_element(by=By.ID, value=\"quick-link-lessons\").click()\n",
    "element = driver.find_element(by=By.CLASS_NAME, value=\"ui_outside-close-component\").click()\n",
    "element= driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "S= lambda X: driver.execute_script('return document.body.parentNode.scroll'+X)\n",
    "driver.set_window_size(S('Width'),S('Height'))\n",
    "driver.find_element_by_tag_name('body').screenshot('chessPage.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring personalization\n",
    "\n",
    "**Exercise 3.2 (30 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you will have to imitate the study described in class on a website of your interest. You will have to measure differences in the content that you receive back from the website under varying treatments. \n",
    "\n",
    "You will have to choose a website and a treatment. Use selenium for this exercise as well. \n",
    "- As for websites, you can pick an online store, or traveling site, some news site, Google News.. basically try to pick something that you suspect gives different results for different searchers. \n",
    "- Examples for treatments would be location, being logged in with an account, history with the website, being on a phone vs a desktop, etc. \n",
    "- You can try to pick multiple searches to make sure you are measuring real phenomenon, not only noise\n",
    "- You can include a control treatment in case you suspect there's A/B testing or noise in how the pages look\n",
    "- Finally you have to pick a measure for the differences on the page. In case you receive items on a page, for example URLs or products, you can define an overlap metric. In case the page is more unstructured, come up with an explanation for how you define differences.\n",
    "\n",
    "As your answer, explain which of the above you chose, how you implemented the experiment, and what difference you found in the pages you collected. \n",
    "\n",
    "You can find more info on how to run multiple browsers at the same time here: https://crossbrowsertesting.com/blog/selenium/run-test-multiple-browsers-parallel-selenium/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import os\n",
    "import time\n",
    "from venv import create\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "\n",
    "def noPreResearchFirefox():\n",
    "    print (\"no Presearch\")\n",
    "    driver = webdriver.Firefox()\n",
    "    driver.get(\"http://www.amazon.com\")\n",
    "    element = driver.find_element(by=By.ID, value=\"twotabsearchtextbox\")\n",
    "    element.send_keys(\"razor\")\n",
    "\n",
    "    driver.find_element(by=By.ID, value=\"nav-search-submit-button\").click()\n",
    "\n",
    "    #When Amazon creats your researchsite every Items has an ID (4,5,6 are not product but other content)   \n",
    "    idListOfItems  = [1,2,3,7,8,9,10,11,12]\n",
    " \n",
    "    for id in idListOfItems:\n",
    "        title =\"noTitle\"\n",
    "        price= \"no Price\"\n",
    "        time.sleep(1)\n",
    "        numero = id\n",
    "        try: \n",
    "            driver.find_element(by=By.CSS_SELECTOR, value='[data-index=\"'+str(numero)+'\"]').click()\n",
    "            time.sleep(1)\n",
    "            for a in range(0, 3):\n",
    "                #if there is not a price\n",
    "                try:\n",
    "                    #dependig of the product the Price is situated in an a place with other Id\n",
    "                    idOfCSSName = ['color_name_'+str(a) +'_price','style_name_'+str(a)+'_price']\n",
    "                    #goes throug the the different CDD id\n",
    "                    for nameCSS in idOfCSSName:\n",
    "                        #tryes to find a price \n",
    "                        try:\n",
    "                            title=driver.find_element(by= By.ID, value=\"productTitle\").text\n",
    "                            price = driver.find_element(by=By.ID, value=nameCSS).text\n",
    "                            # if it finds a price id goes aout of the first loop \n",
    "                            break\n",
    "                        except  NoSuchElementException:     \n",
    "                            #no price found goes stays in the loop \n",
    "                            pass  \n",
    "                    # the first loop doesn't raise a exception goes out of the first loop         \n",
    "\n",
    "                except NoSuchElementException:\n",
    "                    #stays in the second loop because no price is found \n",
    "                    pass\n",
    "\n",
    "                if (price != \"no Price\"):\n",
    "                    break    \n",
    "                \n",
    "            print(str(id)+ ': '+title)     \n",
    "            print(price.strip())\n",
    "            time.sleep(1)\n",
    "            driver.back() \n",
    "            time.sleep(1)\n",
    "        except NoSuchElementException:  \n",
    "            print(\"no element\")\n",
    "            pass\n",
    "    driver.close()\n",
    "    print()\n",
    "    print()    \n",
    "\n",
    "        \n",
    "def preResearchTampons():\n",
    "    driver = webdriver.Firefox()\n",
    "    driver.get(\"http://www.amazon.com\")\n",
    "    element = driver.find_element(by=By.ID, value=\"twotabsearchtextbox\")\n",
    "    print (\"preresearched: Tampons\")\n",
    "    element.send_keys(\"tampons\")\n",
    "    driver.find_element(by=By.ID, value=\"nav-search-submit-button\").click()\n",
    "    time.sleep(2)\n",
    "    element = driver.find_element(by=By.ID, value=\"nav-logo-sprites\").click()\n",
    "\n",
    "    element = driver.find_element(by=By.ID, value=\"twotabsearchtextbox\")\n",
    "    element.send_keys(\"razor\")\n",
    "\n",
    "    driver.find_element(by=By.ID, value=\"nav-search-submit-button\").click()\n",
    "\n",
    "    #When Amazon creats your researchsite every Items has an ID (4,5,6 are not product but other content)   \n",
    "    idListOfItems  = [1,2,3,7,8,9,10,11,12]\n",
    " \n",
    "    for id in idListOfItems:\n",
    "        title =\"noTitle\"\n",
    "        price= \"no Price\"\n",
    "        time.sleep(1)\n",
    "        numero = id\n",
    "        try: \n",
    "            driver.find_element(by=By.CSS_SELECTOR, value='[data-index=\"'+str(numero)+'\"]').click()\n",
    "            time.sleep(1)\n",
    "            for a in range(0, 3):\n",
    "                #if there is not a price\n",
    "                try:\n",
    "                    #dependig of the product the Price is situated in an a place with other Id\n",
    "                    idOfCSSName = ['color_name_'+str(a) +'_price','style_name_'+str(a)+'_price']\n",
    "                    #goes throug the the different CDD id\n",
    "                    for nameCSS in idOfCSSName:\n",
    "                        #tryes to find a price \n",
    "                        try:\n",
    "                            title=driver.find_element(by= By.ID, value=\"productTitle\").text\n",
    "                            price = driver.find_element(by=By.ID, value=nameCSS).text\n",
    "                            # if it finds a price id goes aout of the first loop \n",
    "                            break\n",
    "                        except  NoSuchElementException:     \n",
    "                            #no price found goes stays in the loop \n",
    "                            pass  \n",
    "                    # the first loop doesn't raise a exception goes out of the first loop         \n",
    "\n",
    "                except NoSuchElementException:\n",
    "                    #stays in the second loop because no price is found \n",
    "                    pass\n",
    "\n",
    "                if (price != \"no Price\"):\n",
    "                    break    \n",
    "\n",
    "            print(str(id)+ ': '+title)     \n",
    "            print(price.strip())\n",
    "            time.sleep(1)\n",
    "            driver.back() \n",
    "            time.sleep(1)\n",
    "\n",
    "        except NoSuchElementException:  \n",
    "            print(\"no element\")\n",
    "            pass\n",
    "    print()\n",
    "    print()           \n",
    "    driver.close()        \n",
    "\n",
    "     \n",
    "def preResearchViagra():\n",
    "    driver = webdriver.Firefox()\n",
    "    driver.get(\"http://www.amazon.com\")\n",
    "    element = driver.find_element(by=By.ID, value=\"twotabsearchtextbox\")\n",
    "    print (\"preresearched: Viagra\")\n",
    "    element.send_keys(\"viagra\")\n",
    "    driver.find_element(by=By.ID, value=\"nav-search-submit-button\").click()\n",
    "    time.sleep(2)\n",
    "    element = driver.find_element(by=By.ID, value=\"nav-logo-sprites\").click()\n",
    "\n",
    "    element = driver.find_element(by=By.ID, value=\"twotabsearchtextbox\")\n",
    "    element.send_keys(\"razor\")\n",
    "\n",
    "    driver.find_element(by=By.ID, value=\"nav-search-submit-button\").click()\n",
    "\n",
    "    #When Amazon creats your researchsite every Items has an ID (4,5,6 are not product but other content)   \n",
    "    idListOfItems  = [1,2,3,7,8,9,10,11,12]\n",
    " \n",
    "    for id in idListOfItems:\n",
    "        title =\"noTitle\"\n",
    "        price= \"no Price\"\n",
    "        time.sleep(1)\n",
    "        numero = id\n",
    "        try: \n",
    "            driver.find_element(by=By.CSS_SELECTOR, value='[data-index=\"'+str(numero)+'\"]').click()\n",
    "            time.sleep(1)\n",
    "            for a in range(0, 3):\n",
    "                #if there is not a price\n",
    "                try:\n",
    "                    #dependig of the product the Price is situated in an a place with other Id\n",
    "                    idOfCSSName = ['color_name_'+str(a) +'_price','style_name_'+str(a)+'_price']\n",
    "                    #goes throug the the different CDD id\n",
    "                    for nameCSS in idOfCSSName:\n",
    "                        #tryes to find a price \n",
    "                        try:\n",
    "                            title=driver.find_element(by= By.ID, value=\"productTitle\").text\n",
    "                            price = driver.find_element(by=By.ID, value=nameCSS).text\n",
    "                            # if it finds a price id goes aout of the first loop \n",
    "                            break\n",
    "                        except  NoSuchElementException:     \n",
    "                            #no price found goes stays in the loop \n",
    "                            pass  \n",
    "                    # the first loop doesn't raise a exception goes out of the first loop         \n",
    "\n",
    "                except NoSuchElementException:\n",
    "                    #stays in the second loop because no price is found \n",
    "                    pass\n",
    "\n",
    "                if (price != \"no Price\"):\n",
    "                    break    \n",
    "\n",
    "            print(str(id)+ ': '+title)     \n",
    "            print(price.strip())\n",
    "            time.sleep(1)\n",
    "            driver.back() \n",
    "            time.sleep(1)\n",
    "\n",
    "        except NoSuchElementException:  \n",
    "            print(\"no element\")\n",
    "            pass\n",
    "    driver.close()    \n",
    "    print()\n",
    "    print()           \n",
    "        \n",
    "\n",
    "\n",
    "noPreResearchFirefox()\n",
    "\n",
    "preResearchTampons()\n",
    "\n",
    "preResearchViagra()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In our analysis, our decided to look what are the results when we search for razor on amazon given a different last search hystory of one item.\n",
    "    We decided for Amazon because both of us noticed that the search results in our individual research were different. \n",
    "    For a basecase, we decided to directly search for razor and print the first 9 names and price of the items found. \n",
    "    The other two cases that we did were one where we searched for \\\"tampons\\\" to simulate a research done by a biological woman before doing the research for razor, \n",
    "    and the other one where the first research done is for \\\"viagra\\\" to simulate a research done by a biological man.\n",
    "    We thought that a different research pattern would have brought to a different result, but in all three cases the result was the same.\n",
    "    We guess that it could be that Amazon doesn't look directly at what a user searched just before to display  a different content. \n",
    "    Some pittfals of our testing could be that:\n",
    "        - the search done is not enough to cause a difference,\n",
    "        - the website of Amazon leads us to a standard page because it sees us as a computer and not as a real customer ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
